{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as l\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST Dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = tf.cast(x_train, tf.float32) / 255.\n",
    "x_test = tf.cast(x_test, tf.float32) / 255.\n",
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_cat =  keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_classifier():\n",
    "    inputs = l.Input(shape=(28,28,1))\n",
    "    z = l.Flatten()(inputs)\n",
    "    z = l.Dense(200, activation='relu')(z)\n",
    "    z = l.Dense(100, activation='relu')(z)\n",
    "    output = l.Dense(10, activation='softmax')(z)\n",
    "    \n",
    "    return keras.Model(inputs=[inputs], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4820 - accuracy: 0.8275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f0383c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "simple_clf = create_simple_classifier()\n",
    "simple_clf.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'])\n",
    "simple_clf.fit(x_train, y_train_cat, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard Externsion\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.3902 - accuracy: 0.0938WARNING:tensorflow:From /Users/amandeepsaini/.pyenv/versions/ml1/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.0193s). Check your callbacks.\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4820 - accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3598 - accuracy: 0.8680\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3250 - accuracy: 0.8796\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3017 - accuracy: 0.8887\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2854 - accuracy: 0.8931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f752940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "simple_clf = create_simple_classifier()\n",
    "simple_clf.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'], )\n",
    "simple_clf.fit(x_train, y_train_cat, epochs=5, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets add l1 reg and see how that affects the histograms of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_classifier_reg():\n",
    "    inputs = l.Input(shape=(28,28,1))\n",
    "    z = l.Flatten()(inputs)\n",
    "    z = l.Dense(200, activation='relu', \n",
    "                kernel_regularizer=keras.regularizers.l1(l1=0.01))(z)\n",
    "    z = l.Dense(100, activation='relu',\n",
    "                kernel_regularizer=keras.regularizers.l1(l1=0.01))(z)\n",
    "    output = l.Dense(10, activation='softmax')(z)\n",
    "    \n",
    "    return keras.Model(inputs=[inputs], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 1:19 - loss: 76.6815 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0042s vs `on_train_batch_end` time: 0.0826s). Check your callbacks.\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 2.9996 - accuracy: 0.6771\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.3147 - accuracy: 0.7336\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.2458 - accuracy: 0.7530\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.2088 - accuracy: 0.7623\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1841 - accuracy: 0.7645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141408b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "simple_clf_reg = create_simple_classifier_reg()\n",
    "simple_clf_reg.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'], )\n",
    "simple_clf_reg.fit(x_train, y_train_cat, epochs=5, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 92077), started 0:17:01 ago. (Use '!kill 92077' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2e8918ca898c5602\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2e8918ca898c5602\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the histograms tab, we can see that overtime, the historgams start to have concentrated, sharp peaks, and zeros elsewhere. This is desired with the l1 reg, since we are trying to get sparse weights. This kind of behavior does not happen as strongly without l1 reg, so the visualization showed us that the regularization is indeed making an impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_classifier_cnn():\n",
    "    inputs = l.Input(shape=(28,28,1))\n",
    "    z = l.Conv2D(16, 3, activation='relu')(inputs)\n",
    "    z = l.Conv2D(16, 3, activation='relu')(z)\n",
    "#     z = l.Flatten()(z)\n",
    "    z = l.GlobalAveragePooling2D()(z)\n",
    "    output = l.Dense(10, activation='softmax')(z)\n",
    "    \n",
    "    return keras.Model(inputs=[inputs], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 1:11 - loss: 2.3157 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0288s vs `on_train_batch_end` time: 0.0470s). Check your callbacks.\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 1.3874 - accuracy: 0.5079\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 48s 25ms/step - loss: 0.9943 - accuracy: 0.6530\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.9201 - accuracy: 0.6775\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.8781 - accuracy: 0.6945\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.8459 - accuracy: 0.7075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1433929b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "simple_clf_cnn = create_simple_classifier_cnn()\n",
    "simple_clf_cnn.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'], )\n",
    "simple_clf_cnn.fit(x_train, y_train_cat, epochs=5, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(histogram_freq=1, log_dir=\"logs/trial_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.6469 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0324s). Check your callbacks.\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4825 - accuracy: 0.8267\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3621 - accuracy: 0.8665\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3282 - accuracy: 0.8791\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3046 - accuracy: 0.8874\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2858 - accuracy: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f8377b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.random.set_seed(42)\n",
    "simple_clf = create_simple_classifier()\n",
    "simple_clf.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'], )\n",
    "simple_clf.fit(x_train, y_train_cat, epochs=5, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
